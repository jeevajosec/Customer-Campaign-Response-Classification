# Customer-Campaign-Response-Classification
Project Overview

This project involves classifying customer responses to a campaign using a dataset containing demographic, transactional, and behavioral data. The classification models used are Logistic Regression, Random Forest, and Bagging Classifier. The goal is to predict the target variable Response, which indicates whether a customer responded positively to the campaign.

Dataset

The dataset contains 1680 rows and 31 columns. Below is the description of the columns:

Column Name:Description

Unnamed: 0.1:Index column (not used in analysis).

Unnamed: 0: Secondary index column (not used).

ID: Unique customer identifier.

Year_Birth:Year of birth of the customer.

Education:Customer's level of education.

Marital_Status:Customer's marital status.

Income: Customer's yearly income.

Kidhome: Number of children in the household.

Teenhome: Number of teenagers in the household.

Dt_Customer: Date of customer enrollment.

Recency: Days since the last purchase.

MntCoke: Amount spent on Coke products.

MntFruits:Amount spent on Fruits.

MntMeatProducts: Amount spent on Meat products.

MntFishProducts: Amount spent on Fish products.

MntSweetProducts: Amount spent on Sweet products.

MntGoldProds: Amount spent on Gold products.

NumDealsPurchases: Number of purchases with a deal.

NumWebPurchases: Number of purchases through the website.

NumCatalogPurchases: Number of purchases using catalogs.

NumStorePurchases: Number of purchases directly in stores.

NumWebVisitsMonth: Number of visits to the website in a month.

AcceptedCmp3: Accepted campaign 3 (binary).

AcceptedCmp4: Accepted campaign 4 (binary).

AcceptedCmp5: Accepted campaign 5 (binary).

AcceptedCmp1: Accepted campaign 1 (binary).

AcceptedCmp2: Accepted campaign 2 (binary).

Complain: Complained in the last 2 years (binary).

Z_CostContact: Cost to contact the customer (fixed value).

Z_Revenue: Revenue generated by the customer (fixed).

Response: Target variable indicating campaign response.

Note: The Income column contains 17 missing values, which were imputed before model training.

Preprocessing

Data Cleaning:

Dropped unnecessary columns such as Unnamed: 0.1, Unnamed: 0, and ID.

Handled missing values in the Income column using median imputation.

Feature Encoding:

Encoded categorical variables (Education, Marital_Status) using one-hot encoding.

Feature Scaling:

Applied standard scaling to numerical features to ensure uniformity.

Train-Test Split:

Split the data into training (80%) and testing (20%) sets.

Models and Performance

The following classification models were implemented and evaluated:

Logistic Regression:

Achieved an accuracy of 82.22%.

Random Forest:

Achieved an accuracy of 83.63%. This model performed the best in terms of overall accuracy.

Bagging Classifier:

Achieved an accuracy of 81.69%.

Conclusion

Random Forest was the best-performing model for this classification task. It achieved the highest accuracy, indicating its effectiveness in handling the given dataset with both numerical and categorical features.

Future Work

Perform hyperparameter tuning for all models to further improve performance.

Explore additional ensemble methods such as Gradient Boosting or XGBoost.

Conduct feature selection to identify the most important predictors.

Investigate alternative imputation methods for handling missing values in the Income column.

Dependencies

Python 3.9+

Libraries: pandas, numpy, scikit-learn, matplotlib, seaborn
